{
    "model_id":"../../models/TinyLlama/TinyLlama_v1.1",
    "segment_size":510,
    "cmp_size":34,
    "mem_size":34,
    "cmp_ratio":15,
    "mem_ratio":15,
    "group_size":68,
    "groups_num":2,    
    "num_experts":7,
    "DARK_CMP":0,
    "DARK_MEM":1,
    "SEMANTIC":2,
    "DISCARD_DARK_CMP":3,
    "DISCARD_DARK_MEM":4,
    "NEW_CMP":5,
    "NEW_MEM":6,
    "causal_lm_weight":0.5,
    "cmp_weight":0.5,
    "lora_rank":1,
    "training_args":{
        "output_dir":"../ReCMLLM_outputs/models",
        "do_train":true,
        "do_eval":false,
        "report_to":"wandb",
        "lr_scheduler_type":"constant",
        "optim":"adamw_torch",
        "optim_args":"weight_decay=0.1,beta1=0.9,beta2=0.95",
        "learning_rate":0.0001,
        "gradient_accumulation_steps":4,
        "num_train_epochs":1,
        "per_device_train_batch_size":1,
        "bf16":true,
        "remove_unused_columns":false
    }
}

